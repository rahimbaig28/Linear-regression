{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-15T15:49:52.426102Z",
     "iopub.status.busy": "2025-02-15T15:49:52.425706Z",
     "iopub.status.idle": "2025-02-15T15:49:52.434099Z",
     "shell.execute_reply": "2025-02-15T15:49:52.432909Z",
     "shell.execute_reply.started": "2025-02-15T15:49:52.426068Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T15:49:52.460108Z",
     "iopub.status.busy": "2025-02-15T15:49:52.459715Z",
     "iopub.status.idle": "2025-02-15T15:49:52.479488Z",
     "shell.execute_reply": "2025-02-15T15:49:52.478122Z",
     "shell.execute_reply.started": "2025-02-15T15:49:52.460075Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the training dataset\n",
    "train_path = \"train.csv\"\n",
    "df_train = pd.read_csv(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been trained and saved as 'linear.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Load training data\n",
    "train_path = \"train.csv\"\n",
    "df_train = pd.read_csv(train_path)\n",
    "\n",
    "# Define target variable\n",
    "target_column = df_train.columns[-1]\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "num_cols = df_train.select_dtypes(include=['number']).columns.tolist()\n",
    "cat_cols = df_train.select_dtypes(exclude=['number']).columns.tolist()\n",
    "\n",
    "# Ensure target column is not in numerical columns\n",
    "if target_column in num_cols:\n",
    "    num_cols.remove(target_column)\n",
    "\n",
    "# Drop rows where target is missing\n",
    "df_train = df_train.dropna(subset=[target_column])\n",
    "\n",
    "# Convert target column to float\n",
    "df_train[target_column] = df_train[target_column].astype(float)\n",
    "\n",
    "# Handle missing values\n",
    "num_imputer = SimpleImputer(strategy='mean')\n",
    "df_train[num_cols] = num_imputer.fit_transform(df_train[num_cols])\n",
    "\n",
    "if cat_cols:\n",
    "    cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "    df_train[cat_cols] = cat_imputer.fit_transform(df_train[cat_cols])\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_train[col] = le.fit_transform(df_train[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Splitting features and target\n",
    "X = df_train.drop(columns=[target_column])\n",
    "y = df_train[target_column]\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X[num_cols] = scaler.fit_transform(X[num_cols])\n",
    "\n",
    "# Train the Linear Regression Model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Save the trained model\n",
    "with open(\"linear.pkl\", \"wb\") as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "print(\"Model has been trained and saved as 'linear.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training dataset\n",
    "test_path = \"test.csv\"\n",
    "df_test = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x    0\n",
       "y    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    x          y       y_pred\n",
      "0  77  79.775152  2279.308013\n",
      "1  21  23.177279   657.949363\n",
      "2  22  25.609262   686.902196\n",
      "3  20  17.857388   628.996530\n",
      "4  36  41.849864  1092.241858\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model from the pickle file\n",
    "with open(model_filename, 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "# Prepare the test data (assuming 'x' is the feature column)\n",
    "X_test = df_test[['x']]\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_test_pred = loaded_model.predict(X_test)\n",
    "\n",
    "# Add predictions to the test dataframe\n",
    "df_test['y_pred'] = y_test_pred\n",
    "\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to test_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahim\\AppData\\Local\\Temp\\ipykernel_22956\\3704481018.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[num_cols] = num_imputer.fit_transform(df_test[num_cols])\n",
      "C:\\Users\\rahim\\AppData\\Local\\Temp\\ipykernel_22956\\3704481018.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[num_cols] = scaler.fit_transform(df_test[num_cols])\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Handle missing values in the test dataset\n",
    "num_imputer = SimpleImputer(strategy='mean')\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "num_cols = df_test.select_dtypes(include=['number']).columns.tolist()\n",
    "cat_cols = df_test.select_dtypes(exclude=['number']).columns.tolist()\n",
    "\n",
    "df_test[num_cols] = num_imputer.fit_transform(df_test[num_cols])\n",
    "if cat_cols:\n",
    "    df_test[cat_cols] = cat_imputer.fit_transform(df_test[cat_cols])\n",
    "\n",
    "# Encode categorical variables using LabelEncoder\n",
    "label_encoders = {}\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_test[col] = le.fit_transform(df_test[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Scale numerical features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df_test[num_cols] = scaler.fit_transform(df_test[num_cols])\n",
    "\n",
    "# Ensure the test dataset only contains the features used during training\n",
    "df_test = df_test[X.columns]\n",
    "\n",
    "# Load the trained model\n",
    "with open(\"linear.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "# Make predictions\n",
    "test_predictions = model.predict(df_test)\n",
    "\n",
    "# Save predictions\n",
    "df_test[\"Predictions\"] = test_predictions\n",
    "output_path = \"test_predictions.csv\"\n",
    "df_test.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Predictions saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 1474.7608052980115\n",
      "Mean Squared Error (MSE): 2806865.5348275886\n",
      "Root Mean Squared Error (RMSE): 1675.3702679788694\n",
      "R-squared (RÂ²): -3347.4165221976764\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mae = mean_absolute_error(df_test['Predictions'], y_test_pred)\n",
    "mse = mean_squared_error(df_test['Predictions'], y_test_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(df_test['Predictions'], y_test_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"R-squared (RÂ²): {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##The evaluation metrics for the model's performance on the test dataset indicate \n",
    "# that the model did not perform well. The Mean Absolute Error (MAE) is 1474.76, \n",
    "# which suggests that on average, the model's predictions are off by approximately \n",
    "# 1474.76 units from the actual values. The Mean Squared Error (MSE) is 2806865.53, \n",
    "# and the Root Mean Squared Error (RMSE) is 1675.37, both of which are quite high,\n",
    "# indicating significant errors in the predictions. Additionally, the R-squared (RÂ²) \n",
    "# value is -3347.42, which is extremely poor and suggests that the model fails to \n",
    "# explain the variance in the target variable. An RÂ² value this low indicates that \n",
    "# the model's predictions are worse than simply using the mean of the target variable \n",
    "# as the prediction. Overall, these metrics highlight that the model's predictions are \n",
    "# not reliable and that there is substantial room for improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1256,
     "sourceId": 2242,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
